{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Try to make a model that is both good at size and precision. This time we will try many possibilities."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "391929a7d2022ea"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:09.256239100Z",
     "start_time": "2024-07-11T03:03:09.168694200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "  grid_code  time_stamp  taxi_density  pm2.5_aqi  humidity wind_direction  \\\n0       0@7  1680310800           0.0  52.226051        62              S   \n1       0@8  1680310800           0.0  52.226051        62              S   \n2       0@9  1680310800           0.0  68.886052        62              S   \n3       1@9  1680310800           0.0  68.886052        62              S   \n4       3@6  1680310800           0.0  52.226051        62              S   \n\n         temp  wind_speed  wind_gust     pressure  weather_id  \n0  287.594444      4.4704        0.0  1009.482859         804  \n1  287.594444      4.4704        0.0  1009.482859         804  \n2  287.594444      4.4704        0.0  1009.482859         804  \n3  287.594444      4.4704        0.0  1009.482859         804  \n4  287.594444      4.4704        0.0  1009.482859         804  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>grid_code</th>\n      <th>time_stamp</th>\n      <th>taxi_density</th>\n      <th>pm2.5_aqi</th>\n      <th>humidity</th>\n      <th>wind_direction</th>\n      <th>temp</th>\n      <th>wind_speed</th>\n      <th>wind_gust</th>\n      <th>pressure</th>\n      <th>weather_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0@7</td>\n      <td>1680310800</td>\n      <td>0.0</td>\n      <td>52.226051</td>\n      <td>62</td>\n      <td>S</td>\n      <td>287.594444</td>\n      <td>4.4704</td>\n      <td>0.0</td>\n      <td>1009.482859</td>\n      <td>804</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0@8</td>\n      <td>1680310800</td>\n      <td>0.0</td>\n      <td>52.226051</td>\n      <td>62</td>\n      <td>S</td>\n      <td>287.594444</td>\n      <td>4.4704</td>\n      <td>0.0</td>\n      <td>1009.482859</td>\n      <td>804</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0@9</td>\n      <td>1680310800</td>\n      <td>0.0</td>\n      <td>68.886052</td>\n      <td>62</td>\n      <td>S</td>\n      <td>287.594444</td>\n      <td>4.4704</td>\n      <td>0.0</td>\n      <td>1009.482859</td>\n      <td>804</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1@9</td>\n      <td>1680310800</td>\n      <td>0.0</td>\n      <td>68.886052</td>\n      <td>62</td>\n      <td>S</td>\n      <td>287.594444</td>\n      <td>4.4704</td>\n      <td>0.0</td>\n      <td>1009.482859</td>\n      <td>804</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3@6</td>\n      <td>1680310800</td>\n      <td>0.0</td>\n      <td>52.226051</td>\n      <td>62</td>\n      <td>S</td>\n      <td>287.594444</td>\n      <td>4.4704</td>\n      <td>0.0</td>\n      <td>1009.482859</td>\n      <td>804</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_gird_dataset = pd.read_csv('final_grid_dataset_final.csv')\n",
    "final_gird_dataset.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:11.609304500Z",
     "start_time": "2024-07-11T03:03:09.170617800Z"
    }
   },
   "id": "78a7bd6c5cf95017"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:11.609817500Z",
     "start_time": "2024-07-11T03:03:11.592715700Z"
    }
   },
   "id": "a0e568454c122ab6"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class WindDirectionOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.directional_strings = ['S', 'SSW', 'SW', 'SSE', 'WNW', 'NNW', 'WSW', 'NW', 'N', 'NE', 'ENE', 'E', 'ESE', 'SE', 'NNE', 'W']\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "            \n",
    "        X = X.copy()\n",
    "        X['wind_direction'] = X['wind_direction'].apply(lambda x: x if x in self.directional_strings else 'other')\n",
    "\n",
    "        X_encoded = pd.get_dummies(X, columns=['wind_direction'], prefix='', prefix_sep='')\n",
    "\n",
    "        if 'other' in X_encoded.columns:\n",
    "            X_encoded = X_encoded.drop(columns=['other'])\n",
    "\n",
    "        for col in self.directional_strings:\n",
    "            if col not in X_encoded.columns:\n",
    "                X_encoded[col] = 0\n",
    "\n",
    "        X_encoded = X_encoded[self.directional_strings]\n",
    "        X_encoded = X_encoded.astype(int)\n",
    "\n",
    "        return X_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:11.611125800Z",
     "start_time": "2024-07-11T03:03:11.601939100Z"
    }
   },
   "id": "ffeec13d15b304d0"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class WindDirectionTwoDimensionalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.directional_map = {\n",
    "            'N': (1.0, 0.0),        # 0°\n",
    "            'NNE': (0.966, 0.259),  # 22.5°\n",
    "            'NE': (0.866, 0.5),     # 45°\n",
    "            'ENE': (0.707, 0.707),  # 67.5°\n",
    "            'E': (0.5, 0.866),      # 90°\n",
    "            'ESE': (0.259, 0.966),  # 112.5°\n",
    "            'SE': (0.0, 1.0),       # 135°\n",
    "            'SSE': (-0.259, 0.966), # 157.5°\n",
    "            'S': (-0.5, 0.866),     # 180°\n",
    "            'SSW': (-0.707, 0.707), # 202.5°\n",
    "            'SW': (-0.866, 0.5),    # 225°\n",
    "            'WSW': (-0.966, 0.259), # 247.5°\n",
    "            'W': (-1.0, 0.0),       # 270°\n",
    "            'WNW': (-0.966, -0.259),# 292.5°\n",
    "            'NW': (-0.866, -0.5),   # 315°\n",
    "            'NNW': (-0.707, -0.707) # 337.5°\n",
    "        }\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        X['cos'] = X['wind_direction'].apply(lambda x: self.directional_map.get(x, (0.0, 0.0))[0])\n",
    "        X['sin'] = X['wind_direction'].apply(lambda x: self.directional_map.get(x, (0.0, 0.0))[1])\n",
    "\n",
    "        return X[['cos', 'sin']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:11.626576900Z",
     "start_time": "2024-07-11T03:03:11.614155700Z"
    }
   },
   "id": "a80b1e984fa81e05"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class WeatherIdEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.weather_ids = [804, 500, 741, 803, 801, 800, 200, 501, 721, 300, 211, 502, 711, 212, 701, 600, 616, 612, 511, 601, 602, 301]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "            \n",
    "        X = X.copy()\n",
    "        X['weather_id'] = X['weather_id'].apply(lambda x: x if x in self.weather_ids else 'other')\n",
    "\n",
    "        X_encoded = pd.get_dummies(X, columns=['weather_id'], prefix='', prefix_sep='')\n",
    "\n",
    "        if 'other' in X_encoded.columns:\n",
    "            X_encoded = X_encoded.drop(columns=['other'])\n",
    "\n",
    "        for weather_id in self.weather_ids:\n",
    "            if str(weather_id) not in X_encoded.columns:\n",
    "                X_encoded[str(weather_id)] = 0\n",
    "\n",
    "        X_encoded = X_encoded[[str(weather_id) for weather_id in self.weather_ids]]\n",
    "        X_encoded = X_encoded.astype(int)\n",
    "\n",
    "        return X_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:11.659615900Z",
     "start_time": "2024-07-11T03:03:11.619090Z"
    }
   },
   "id": "b659181cfa22e86b"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class GridCodeTwoDimensionalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        \n",
    "        X = X.copy()\n",
    "        X[['grid_x', 'grid_y']] = X['grid_code'].str.split('@', expand=True).astype(int)\n",
    "        return X.drop(columns=['grid_code'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:11.665220200Z",
     "start_time": "2024-07-11T03:03:11.628592900Z"
    }
   },
   "id": "483cb786c1e55419"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class TimestampEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        X['month'] = pd.to_datetime(X['time_stamp'], unit='s').dt.month\n",
    "        X['day_of_week'] = pd.to_datetime(X['time_stamp'], unit='s').dt.weekday\n",
    "        X['hour_of_day'] = pd.to_datetime(X['time_stamp'], unit='s').dt.hour\n",
    "\n",
    "        X = X.drop(columns=['time_stamp'])\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:11.722280100Z",
     "start_time": "2024-07-11T03:03:11.635642400Z"
    }
   },
   "id": "157901904c925e56"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38300173a39ed25f"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:11.722280100Z",
     "start_time": "2024-07-11T03:03:11.639273100Z"
    }
   },
   "id": "d4288bd6041f3aa5"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 358 grid_codes.\n",
      "test set: 608600\n",
      "train set: 2434042\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for grid_code, group in final_gird_dataset.groupby('grid_code'):\n",
    "    train_set_one_grid, test_set_one_grid = train_test_split(group, test_size=0.2, random_state=42)\n",
    "\n",
    "    if count == 0:\n",
    "        train_set = train_set_one_grid\n",
    "        test_set = test_set_one_grid\n",
    "    else:\n",
    "        train_set = pd.concat([train_set, train_set_one_grid], axis=0)\n",
    "        test_set = pd.concat([test_set, test_set_one_grid], axis=0)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "print(f'Total: {count} grid_codes.')\n",
    "print(f'test set: {len(test_set)}')\n",
    "print(f'train set: {len(train_set)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:22.715533800Z",
     "start_time": "2024-07-11T03:03:11.644933Z"
    }
   },
   "id": "912a12d5725e3501"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining inputs and outputs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b936e2654375b3c"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "taxi_model_inputs = ['grid_code', 'time_stamp', 'humidity', 'wind_direction', 'temp', 'wind_speed', 'wind_gust', 'pressure', 'weather_id']\n",
    "taxi_model_output = 'taxi_density' \n",
    "aqi_model_inputs = ['grid_code', 'time_stamp', 'taxi_density', 'humidity', 'wind_direction', 'temp', 'wind_speed', 'wind_gust', 'pressure', 'weather_id']\n",
    "aqi_model_output = 'pm2.5_aqi'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:23.651258300Z",
     "start_time": "2024-07-11T03:03:23.641209500Z"
    }
   },
   "id": "dff6a8dcd1265d69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Batch experiments\n",
    "Encoder configurations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f964b567016681ee"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from copy import deepcopy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:23.663372700Z",
     "start_time": "2024-07-11T03:03:23.648143200Z"
    }
   },
   "id": "169f125c0e2fe4ca"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "wind_direction_encoders = [WindDirectionOneHotEncoder(), WindDirectionTwoDimensionalEncoder()]\n",
    "timestamp_encoders = [None, TimestampEncoder()]\n",
    "weather_id_encoder = WeatherIdEncoder()\n",
    "grid_code_encoder = GridCodeTwoDimensionalEncoder()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:23.663372700Z",
     "start_time": "2024-07-11T03:03:23.657573700Z"
    }
   },
   "id": "7bf90762e9993233"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model configuration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4372610aed2b45d"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "models = {\n",
    "    'linear_regression': \"LinearRegression()\",\n",
    "    'decision_tree': \"DecisionTreeRegressor()\",\n",
    "    'random_forest_small': \"RandomForestRegressor(n_estimators=50, max_depth=10, min_samples_split=20, min_samples_leaf=10, n_jobs=-1, random_state=42)\",\n",
    "    'random_forest_complex': \"RandomForestRegressor(n_estimators=100, max_depth=70, min_samples_split=5, min_samples_leaf=2, n_jobs=-1, random_state=42)\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:23.672937800Z",
     "start_time": "2024-07-11T03:03:23.663372700Z"
    }
   },
   "id": "2d1eea198dfc241"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class PrintData(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):          \n",
    "        print(\"Transformed Data:\")\n",
    "        print(X[1])\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:23.696319300Z",
     "start_time": "2024-07-11T03:03:23.668239700Z"
    }
   },
   "id": "1967ff3809f4b421"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def run_experiments(train_set, test_set, wind_dir_encoders, timestamp_encoders, models):\n",
    "    results = []\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        \n",
    "        print(f'------ {model_name} ------')\n",
    "        count = 0\n",
    "        \n",
    "        for wind_dir_encoder, timestamp_encoder in itertools.product(wind_dir_encoders, timestamp_encoders):\n",
    "            count += 1\n",
    "            print(f'configuration {count}....')\n",
    "            \n",
    "            train_set = train_set.copy()\n",
    "            test_set = test_set.copy()\n",
    "            \n",
    "            preprocessors = [('wind_direction', wind_dir_encoder, ['wind_direction']), \n",
    "                                  ('weather_id', weather_id_encoder, ['weather_id']), \n",
    "                                  ('grid_code', grid_code_encoder, ['grid_code'])]\n",
    "            \n",
    "            if timestamp_encoder:\n",
    "                preprocessors.append(('time_stamp', timestamp_encoder, ['time_stamp']))\n",
    "                \n",
    "            # Taxi model\n",
    "            taxi_pipeline = Pipeline([\n",
    "                ('preprocessor', ColumnTransformer(deepcopy(preprocessors), remainder='passthrough')),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', eval(model))\n",
    "            ])\n",
    "            \n",
    "            taxi_pipeline.fit(train_set[taxi_model_inputs], train_set[taxi_model_output])\n",
    "            \n",
    "            # AQI model\n",
    "            aqi_pipeline = Pipeline([\n",
    "                ('preprocessor', ColumnTransformer(deepcopy(preprocessors), remainder='passthrough')),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', eval(model))\n",
    "            ])\n",
    "            \n",
    "            aqi_pipeline.fit(train_set[aqi_model_inputs], train_set[aqi_model_output])\n",
    "            \n",
    "            # Test 1\n",
    "            aqi_test_inputs = test_set[aqi_model_inputs].copy()\n",
    "            aqi_test_inputs['taxi_density'] = taxi_pipeline.predict(test_set[taxi_model_inputs])\n",
    "            cascade_preds = aqi_pipeline.predict(aqi_test_inputs)\n",
    "            cascade_rmse = root_mean_squared_error(test_set[aqi_model_output], cascade_preds)\n",
    "            \n",
    "            del taxi_pipeline, aqi_pipeline\n",
    "            \n",
    "            # Non cascade model            \n",
    "            non_cascade_pipeline = Pipeline([\n",
    "                ('preprocessor', ColumnTransformer(deepcopy(preprocessors), remainder='passthrough')),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', eval(model))\n",
    "            ])\n",
    "            \n",
    "            non_cascade_pipeline.fit(train_set[taxi_model_inputs], train_set[aqi_model_output])\n",
    "            \n",
    "            # Test 2\n",
    "            non_cascade_preds = non_cascade_pipeline.predict(test_set[taxi_model_inputs])\n",
    "            non_cascade_rmse = root_mean_squared_error(test_set[aqi_model_output], non_cascade_preds)\n",
    "            \n",
    "            del non_cascade_pipeline\n",
    "            \n",
    "            results.append({\n",
    "                'model': model_name,\n",
    "                'wind_direction_encoder': wind_dir_encoder.__class__.__name__,\n",
    "                'timestamp_encoder': timestamp_encoder.__class__.__name__ if timestamp_encoder else 'None',\n",
    "                'cascade_rmse': cascade_rmse,\n",
    "                'non_cascade_rmse': non_cascade_rmse\n",
    "            })\n",
    "    \n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:03:23.696319300Z",
     "start_time": "2024-07-11T03:03:23.672937800Z"
    }
   },
   "id": "5bfbdd6086a894ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Execute the test."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8acb025ce6f1640b"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ linear_regression ------\n",
      "configuration 1....\n",
      "configuration 2....\n",
      "configuration 3....\n",
      "configuration 4....\n",
      "------ decision_tree ------\n",
      "configuration 1....\n",
      "configuration 2....\n",
      "configuration 3....\n",
      "configuration 4....\n",
      "------ random_forest_small ------\n",
      "configuration 1....\n",
      "configuration 2....\n",
      "configuration 3....\n",
      "configuration 4....\n",
      "------ random_forest_complex ------\n",
      "configuration 1....\n",
      "configuration 2....\n",
      "configuration 3....\n",
      "configuration 4....\n"
     ]
    }
   ],
   "source": [
    "experiment_results = run_experiments(train_set, test_set, wind_direction_encoders, timestamp_encoders, models)\n",
    "\n",
    "results_df = pd.DataFrame(experiment_results)\n",
    "results_df.to_csv('model_experiment_results.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T04:22:22.175645200Z",
     "start_time": "2024-07-11T03:03:23.683366400Z"
    }
   },
   "id": "135c40a12a006b75"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best choice is a random forest model with complex parameters, no timestamp encoder and non-cascade structure."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8d955ed249cd78b"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import joblib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T04:22:22.247450300Z",
     "start_time": "2024-07-11T04:22:22.172677700Z"
    }
   },
   "id": "2b671fda71b51d53"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def train_model_on_full_set(dataset, wind_dir_encoder, timestamp_encoder, model, is_cascade):\n",
    "    preprocessors = [('wind_direction', wind_dir_encoder, ['wind_direction']), \n",
    "                          ('weather_id', weather_id_encoder, ['weather_id']), \n",
    "                          ('grid_code', grid_code_encoder, ['grid_code'])]\n",
    "    \n",
    "    if timestamp_encoder:\n",
    "        preprocessors.append(('time_stamp', timestamp_encoder, ['time_stamp']))\n",
    "    \n",
    "    if is_cascade:\n",
    "        taxi_pipeline = Pipeline([\n",
    "            ('preprocessor', ColumnTransformer(deepcopy(preprocessors), remainder='passthrough')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', eval(model))\n",
    "        ])\n",
    "        taxi_pipeline.fit(dataset[taxi_model_inputs], dataset[taxi_model_output])\n",
    "        \n",
    "        joblib.dump(taxi_pipeline, 'taxi_density_model.pkl')\n",
    "        \n",
    "        aqi_pipeline = Pipeline([\n",
    "            ('preprocessor', ColumnTransformer(deepcopy(preprocessors), remainder='passthrough')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', eval(model))\n",
    "        ])\n",
    "        aqi_pipeline.fit(dataset[aqi_model_inputs], dataset[aqi_model_output])\n",
    "        \n",
    "        joblib.dump(aqi_pipeline, 'aqi_model.pkl')\n",
    "    \n",
    "    else:\n",
    "        non_cascade_pipeline = Pipeline([\n",
    "            ('preprocessor', ColumnTransformer(deepcopy(preprocessors), remainder='passthrough')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', eval(model))\n",
    "        ])\n",
    "        non_cascade_pipeline.fit(dataset[taxi_model_inputs], dataset[aqi_model_output])\n",
    "        \n",
    "        joblib.dump(non_cascade_pipeline, 'non_cascade_model.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T04:22:22.248729Z",
     "start_time": "2024-07-11T04:22:22.247450300Z"
    }
   },
   "id": "e7cb29f5ad0cec07"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "train_model_on_full_set(dataset=final_gird_dataset, \n",
    "                        wind_dir_encoder=WindDirectionTwoDimensionalEncoder(),\n",
    "                        timestamp_encoder=None,\n",
    "                        model='RandomForestRegressor(n_estimators=100, max_depth=70, min_samples_split=5, min_samples_leaf=2, n_jobs=-1, random_state=42)',\n",
    "                        is_cascade=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T04:27:08.264388Z",
     "start_time": "2024-07-11T04:22:22.247450300Z"
    }
   },
   "id": "7a05a526ae9f03e9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
